\documentclass{InsightArticle}

\usepackage[dvips]{graphicx}
\usepackage{float}
\usepackage[hang]{subfigure}

\usepackage[dvips,
bookmarks,
bookmarksopen,
backref,
colorlinks,linkcolor={blue},citecolor={blue},urlcolor={blue},
]{hyperref}

\title{A Patch-Based Inpainting Framework}

% 
% NOTE: This is the last number of the "handle" URL that 
% The Insight Journal assigns to your paper as part of the
% submission process. Please replace the number "1338" with
% the actual handle number that you get assigned.
%
\newcommand{\IJhandlerIDnumber}{3250}

% Increment the release number whenever significant changes are made.
% The author and/or editor can define 'significant' however they like.
\release{0.00}

% At minimum, give your name and an email address.  You can include a
% snail-mail address if you like.

\author{David Doria}
\authoraddress{Rensselaer Polytechnic Institute, Troy NY}

\begin{document}

\IJhandlefooter{\IJhandlerIDnumber}


\ifpdf
\else
   %
   % Commands for including Graphics when using latex
   % 
   \DeclareGraphicsExtensions{.eps,.jpg,.gif,.tiff,.bmp,.png}
   \DeclareGraphicsRule{.jpg}{eps}{.jpg.bb}{`convert #1 eps:-}
   \DeclareGraphicsRule{.gif}{eps}{.gif.bb}{`convert #1 eps:-}
   \DeclareGraphicsRule{.tiff}{eps}{.tiff.bb}{`convert #1 eps:-}
   \DeclareGraphicsRule{.bmp}{eps}{.bmp.bb}{`convert #1 eps:-}
   \DeclareGraphicsRule{.png}{eps}{.png.bb}{`convert #1 eps:-}
\fi


\maketitle


\ifhtml
\chapter*{Front Matter\label{front}}
\fi

\begin{abstract}
\noindent
This document describes a system to fill a hole in an image by copying patches from elsewhere in the image. These patches should be a good continuation of the image outside the hole boundary into the hole. The implementation is very generic, allowing the develop to select or easily add new methods for the patch priority order, patch comparison function, and other parameters of the algorithm.

The ``basic'' algorithm is called ClassicalImpageInpainting and is based on the algorithm described in ``Object Removal by Exemplar-Based Inpainting'' (Criminisi et. al.).

The code is available here:
https://github.com/daviddoria/PatchBasedInpainting

\end{abstract}

\IJhandlenote{\IJhandlerIDnumber}

\tableofcontents
\section{Introduction}
This document describes a system to fill a hole in an image by copying patches from elsewhere in the image. These patches should be a good continuation of the hole boundary into the hole. The patch copying is done in an order which attempts to preserve linear structures in the image.

\section{Dependencies}
This code makes heavy use of multiple libraries:

\begin{itemize}
 \item VTK $>=$ 6.0
 \item ITK $>=$ 4.2
 \item Boost $>=$ 1.51
 \item CMake $>=$ 2.8.6
 \item Qt $>=$ 4.8
\end{itemize}

The code is also organized into git submodules. These are included if you clone with:
\begin{verbatim}
git clone --recursive https://github.com/daviddoria/PatchBasedInpainting.git 
\end{verbatim}

or 

\begin{verbatim}
git clone https://github.com/daviddoria/PatchBasedInpainting.git
git submodule update --init --recursive
\end{verbatim}

The required submodules are:

\begin{itemize}
 \item Mask - This submodule contains a set of classes for indicating a hole (to inpaint) in an image. It has functions to do things such as count the number of hole/valid pixels in a region, computed the gradient of a region without considering the values at masked pixels, etc.
 \item ITKHelpers (via Mask) - This submodule contains functions we commonly need to operate on ITK data structures. For example, it includes functions to extract the pixel values at specified pixel locations, extract channels of an image, etc.
 \item Helpers (via Mask\\ITKHelpers) - This submodule contains helper functions for the c++ language. It includes functions to do things such as writing a vector to a stream, check if a vector contains a specified value, compute the maximum of each channel of a vector container, etc. It also includes a Statistics class to compute averages, variances, etc. of multicomponent containers.
 \item BoostHelpers - This submodule allows us to do things such as inspect the values in a property map, output the values in a queue, etc.
 \item CMakeHelpers - This submodule allows us to use the submodule hierarchy in a much more straightforward fashion.
 \item ITKQtHelpers - This submodule allows us to convert back and forth between ITK and Qt data structures (images), which is needed to display patches from an itk::Image in a QGraphicsView.
 \item ITKVTKCamera - This submodule allows us to easily compensate for the difference in coordinate system between ITK and VTK.
 \item ITKVTKHelpers - This submodule allows us to convert back and forth between ITK and VTK data structures (images). For example, when we want to display an itk::Image in a vtkRenderer, we must first convert it to a vtkImageData.
 \item QtHelpers - This submodule provides functions to simplify some tasks for QImage (setting an image to a constant value, etc) and working with colors in Qt.
 \item VTKHelpers - This submodule contains many functions that we repeatedly need for VTK, including things like constructing a transparent image, outlining a region of an image, etc.
\end{itemize}

\section{Terminology}
Throughout this document, the ``source region'' is the portion of the image which is known (is not part of the hole) at the beginning. The ``target region'' is the current hole to be filled.

\section{Basic Algorithm Overview}
The inputs to the algorithm consist of an image and a binary mask the same size as the image. We use a custom Mask class to describe the hole (https://github.com/daviddoria/Mask). Throughout this paper, we have colored the region in the input image corresponding to the hole bright green. This color irrelevant - we have done this only to make it obvious to tell if any part of the hole remains after inpainting (it should not), and for easier debugging to ensure these pixels are not used in any part of the computation. In practice, the input image need not be modified.

\section{Algorithm Synthetic Demonstration}
Figure \ref{fig:SyntheticDemonstration} shows a synthetic demonstration of the algorithm. The image consists of a black region (top) and a gray region (bottom).  This simple example is used for testing because we know the result to expect - the dividing line between the black region and gray region should be continued smoothly.

\begin{figure}[H]
\centering
\subfigure[Image to be filled. The region to be filled is shown in bright green.]
  {
  \includegraphics[width=0.3\linewidth]{images/BlackWhite}
  \label{fig:SyntheticDemonstration:ExampleInputImage}
  }
\subfigure[The mask of the region to inpaint.]
  {
  \includegraphics[width=0.3\linewidth]{images/BlackWhiteMask}
  \label{fig:SyntheticDemonstration:ExampleInputMask}
  }
\subfigure[The result of the inpainting.]
  {
  \includegraphics[width=0.3\linewidth]{images/BlackWhiteResult}
  \label{fig:SyntheticDemonstration:ExampleInputOutput}
  }
\caption{Synthetic Demonstration}
\label{fig:SyntheticDemonstration}
\end{figure}

\section{Realistic Demonstration}
Figure \ref{fig:RealisticDemonstration} shows a real example of the algorithm. This result shows the typical quality of inpainting that the algorithm produces. 

\begin{figure}[H]
\centering
\subfigure[Image to be filled. The region to be filled is shown in bright green.]
  {
  \includegraphics[width=0.3\linewidth]{images/Bungee}
  \label{fig:RealisticDemonstration:ExampleInputImage}
  }
\subfigure[The mask of the region to inpaint.]
  {
  \includegraphics[width=0.3\linewidth]{images/BungeeMask}
  \label{fig:RealisticDemonstration:ExampleInputMask}
  }
\subfigure[The result of the inpainting. This took about 30 seconds on a P4 3GHz processor with a 206x308 image and a patch radius = 5.]
  {
  \includegraphics[width=0.3\linewidth]{images/BungeeResult}
  \label{fig:RealisticDemonstration:ExampleInputOutput}
  }
\caption{Realistic Demonstration}
\label{fig:RealisticDemonstration}
\end{figure}

\section{Algorithm Structure}
An overview of the algorithm is:
\begin{itemize}
  \item Initialize:
    \begin{itemize}
      \item Read an image and a binary mask. Non-zero pixels in the mask describe the hole to fill.
      \item Set the size of the patches which will be copied. (Typically an 11x11 patch (patch radius = 5) is used).
      \item Locate all patches of the image which are completely inside the image and completely in the source region. These are stored as an $std::vector<itk::ImageRegion<2> >$ named SourcePatches.
    \end{itemize}

  \item Main loop:
  \begin{itemize}
    \item Compute the priority of every pixel on the hole boundary (see Section \ref{subsec:AlgorithmDetails:Priorities})
    \item Determine the boundary pixel with the highest priority. We will call this the target pixel. The region centered at the target pixel and the size of the patches is called the target patch.
    \item Find the source Pptch which best matches the portion of the target patch in the source region.
    \item Copy the corresponding portion of the source patch into the target region of the target patch.
    \item Repeat until the target region consists of zero pixels.
  \end{itemize}
\end{itemize}

%%%%%%%%%%%%%%%%%%
\section{Priority Functions}
\label{sec:PriorityFunctions}
The priority function is used to determine which target patch to fill next. We provide several such functions.

\subsection{PriorityCriminisi}
The priority term described in \cite{criminisi} is is given by the product of a Confidence term $C(p)$ and a Data term $D(p)$. This priority function attempts to both continue linear structures sooner rather than later, and fill patches where a larger number of the pixels in the patch are already filled.

\subsection{PriorityConfidence}
This priority function is the confidence term from the Criminisi priority function. Using this function essentially makes the algorithm fill patches from the outside of the hole and work its way inward.

\subsection{PriorityRandom}
This priority function selects a random target node to fill next. It is probably best to only use this ordering for debugging.

%%%%%%%%%%%%%%%%
\section{Patch Difference Functions}
\label{sec:PatchMatching}
Patch comparisons can be done between corresponding pixels or using non-pixel specific metrics. Several patch difference functions are provided.

\subsection{ImagePatchDifference}
This is the ``standard'' patch difference function that computes a sum of differences of corresponding pixels in two patches. It is templated on the comparison to be performed on each pair of corresponding pixels.

\subsection{GMHDifference}
This function computes the difference between the gradient magnitude histogram of the valid region of the target patch and the gradient magnitude histogram of the entire source patch. 

%%%%%%%%%%%%%%%%
\section{Pixel Difference Functions}
\label{sec:PatchMatching}
The ImagePatchDifference class described above requires a function to compute the difference between pixels. Several such distance functions are provided, and the most notable ones are described here.

\subsection{SumSquaredPixelDifference (SSD)}
This function computes the sum of squared differences between every pixel in the valid region of the target patch and its corresponding pixel in the source patch. This is the standard difference function used in patch-based inpainting (e.g. \cite{criminisi}). This function is generic for any pixel type that has an operator[], but is specialized for pixels of type itk::CovariantVector. We also provide an explicitly unrolled version of this function, as since it is at the heart of the algorithm and the computational bottleneck, we have tried to do everything possible to ensure it runs as fast as possible.

\subsection{SumAbsolutePixelDifference (SAD)}
This function computes the sum of absolute differences between ND pixels. This function is generic for any pixel type that has an operator[], but is specialized for pixels of type itk::CovariantVector. We also provide an explicitly unrolled version of this function, as since it is at the heart of the algorithm and the computational bottleneck, we have tried to do everything possible to ensure it runs as fast as possible.

\subsection{WeightedSumSquaredPixelDifference}
This function computes a weighted sum of squared differences between ND pixels.

\subsection{HSVSSD}
The standard SSD function is acceptable if the image is represented in a color space (like RGB) where each channel is ``non-wrapping''. That is, the values in the upper range of the channel (255) should be significantly different from the values in the lower range of the channel (0). This is not the case with the H channel of the HSV color space, so we must treat its cyclic nature specially. In this class, we treat the S and V channels as ``standard'' channels, and use a special difference functor for the H channel that takes into account that we are measuring an angular distance and that wrapping over the upper range (1) back into the lower range (0) does not indicate an enormous difference, but rather we handle it correctly.

%%%%%%%%%%%%%%%
\section{Drivers}
As you will have noticed, the code is very heavily templated. A substantial amount of code is required to setup the objects to pass to the algorithm. To prevent code duplication when wanting to use the same algorithm in two contexts (for example, we may want a version of ClassicalImpageInpainting that displays its progress as it goes along and another that does not), we have separated this setup functionality into what we call a \emph{driver}. This allows us to separate the data preparation from this algorithm setup. For example, We have root/ClassicalImageInpainting.cpp and root/ClassicalImageInpaintingBasicViewer.cpp both of which use the ClassicalImpageInpainting driver.

%%%%%%%%%%%%%%%
\section{Interactivity}
We have drivers for each of our algorithms that are called by executables with matching names that are purely terminal programs. That is, they require no GUI context to be created (they do not display anything) and do not require any GUI input from the user (they do not ask questions using QDialog, etc). In these cases, the algorithm  (i.e. InpaintingAlgorithm) can be invoked as a normal function call.

However, in the case that we want to either display the intermediate progress (using BasicViewer) or prompt the user to do something like select a patch (for example, TopPatchesDialog), we must run the algorithm in a different thread so that the GUI stays responsive during the algorithm. As an example, refer to ClassicalImageInpaintingBasicViewer. Here the last line calls InpaintingAlgorithm, but is wrapped in a QtConcurrent::run call (which also requires boost::bind since the InpaintingAlgorithm is a function template). This starts the algorithm in a separate thread, and returns from the driver function to hit the app.exec() at the end of main() which triggers the GUI thread loop to start. Because of this behavior, and objects allocated on the stack (locals) in the driver function will immediately go out of scope, and nothing will work (everything will crash because the objects are no longer valid).

%%%%%%%%%%%%%%%
\section{Visitors}
In this code we heavily use the \emph{visitor pattern}. The idea is that the algorithm is specified as a very non-specific routine which can be filled in by the developer specifying the particular action that should be taken at each step in the algorithm. This really aligns code with the definition of ``algorithm'' that might be used outside of a programming context. As a simple example, consider the following algorithm:

\begin{verbatim}
 
void Algorithm(VisitorType visitor)
{
  while(not done)
  {
    currentObject = ...;
    visitor.Initialize(currentObject);
    visitor.Process(currentObject);
    visitor.Finalize(currentObject);
  }
}
\end{verbatim}

Here, as long as your visitor knows how to initialize, process, and finalize an object, it can be used with this algorithm. For example,

\begin{verbatim}
 
struct MyVisitor
{
  void Initialize(Object currentObject)
  {
    cout << "init.";
  }

  void Process(Object currentObject)
  {
    cout << "process.";
  }

  void Finalize(Object currentObject)
  {
    cout << "finalize.";
  }
};

...
MyVisitor myVisitor;
Algorithm(myVisitor);
...

\end{verbatim}

Will run the algorithm with the above dummy visitor, which will simply write out the name of each function as it is called.

\subsection{Acceptance Visitors}
These visitors, used with InpaintingAlgorithmWithVerification, take a source and target patch and determine if they are acceptable, usually by comparing some difference function to a threshold. For example, GMHAcceptanceVisitor uses the GMHDifference functor and then compares that value to a specified threshold. If the distance is below the threshold, the acceptance visitor returns true (acceptable), and otherwise returns false (not acceptable).

\subsection{Information Visitors}
\subsection{Descriptor Visitors}

%%%%%%%%%%%%%%%
\section{Utilities}
One of the main components of our inpainting algorithm is a priority queue that tracks which pixels are on the current hole boundary and maintains their priority. This problem is harder than it sounds. We have created an indirect priority queue that is a wrapper around boost::heap::binomial_heap. The trouble is that we often will have nodes in the queue that get invalidated (when the boundary changes, pixels currently in the queue are no longer valid boundary pixels), so we should not process those nodes when they get to the top of the queue. We also must provide a mechanism for changing the priority values associated with nodes that are already in the queue, which we do by storing those values in a property map and using a boost::indirect_cmp to sort the queue. The result is an easy to use queue that does what is expected of a boundary node queue for inpainting.

This directory also contains other helper functions (PatchHelpers) we need for some inpainting algorithms.
%%%%%%%%%%%%%%%
\section{Implementation Details}
\label{sec:ImplementationDetails}

\subsection{Isophotes}
An isophotes is simply a gradient vector rotated by 90 degrees. It indicates the direction of ``same-ness'' rather than the direction of maximum difference. There is a small trick, however, to computing the isophotes. We originally tried to compute the isophotes using the following procedure:

\begin{itemize}
 \item Convert the RGB image to a grayscale image.
 \item Blur the grayscale image.
 \item Compute the gradient using itkGradientImageFilter.
 \item Rotate the resulting vectors by 90 degrees.
 \item Keep only the values in the source region.
\end{itemize}

This procedure produces the gradient magnitude map shown in Figure \ref{fig:ErroneousGradient}.
\begin{figure}[H]
  \centering
  \includegraphics[width=0.3\linewidth]{images/ErroneousGradient}
  \caption{Result of naively computing the image gradient.}
  \label{fig:ErroneousGradient}
\end{figure}

The high values of the gradient magnitude surrounding the target region are very troublesome. The resulting gradient magnitude image using this technique is sensitive to the choice of the pixel values in the target region, which we actually want to be a completely arbitrary choice (it should not affect anything). More importantly, the gradient plays a large part in the computation of the pixel priorities, and this computation is greatly disturbed by these erroneous values. Simply ignoring these boundary isophotes is not an option because the isophotes on the boundary are exactly the ones that are used in the computation of the Data term. To fix this problem, we immediately dilate the mask specified by the user. This allows us to compute the isophotes as described above, but now we have image information on both sides of the hole boundary, leading to a valid gradient everywhere we need it to be. Figure \ref{fig:ErrorneousGradientCorrection} shows the procedure for fixing this problem.

\begin{figure}[H]
\centering
\subfigure[Image to be filled. The target region is shown in green.]
  {
  \includegraphics[width=0.3\linewidth]{images/BlackWhite}
  \label{fig:ErrorneousGradientCorrection:InputImage}
  }
\subfigure[The dilated mask.]
  {
  \includegraphics[width=0.3\linewidth]{images/BlackWhiteDilatedMask}
  \label{fig:ErrorneousGradientCorrection:InputDilated}
  }
\subfigure[The gradient magnitude with pixels in the new (enlarged) target region set to zero.]
  {
  \includegraphics[width=0.3\linewidth]{images/MaskedGradientMagnitude}
  \label{fig:ErrorneousGradientCorrection:Output}
  }
\caption{Procedure for fixing the erroneous gradient problem.}
\label{fig:ErrorneousGradientCorrection}
\end{figure}

As you can see, this gradient magnitude image is exactly what we would expect.

\subsection{Boundary Normals}
There are two things to be careful with when computing the boundary normals: computing the normals only on the one pixel thick boundary, and using the correct side of the masked region as the boundary.

\subsubsection{Computing boundary normals only on the one pixel thick boundary}
If we compute the normals directly on the binary mask, the set of resulting vectors are too discretized to be of use. Therefore, we first blur the mask. However, the gradient of the blurred mask results in non-zero vectors in the gradient image in many more pixels (a ``thick'' boundary) than the gradient of the original mask (a single pixel ``thin'' boundary). Therefore, we must mask the gradient of the blurred mask to keep only the pixels which would have been non-zero in the original mask gradient.


\subsubsection{Using the correct side of the masked region as the boundary}
There are two potential boundaries that can be extracted from a masked region - the ``inner'' boundary and the ``outer'' boundary. As shown in Figure \ref{fig:BoundarySide}, the inner boundary (red) is composed of pixels originally on the white (masked) side of the blob, and the outer boundary (green) is composed of pixels originally on the black (unmasked) side of the blob. It is important that we use the outer boundary, because we need the boundary to be defined at the same pixels that we have image information, which is only in the source (black/unmasked) region.

\begin{figure}[H]
\centering
\subfigure[The inner boundary.]
  {
  \includegraphics[width=0.3\linewidth]{images/BlackWhiteMask}
  \label{fig:BoundarySide:Mask}
  }
\subfigure[Outer boundary (green) and inner boundary (red).]
  {
  \includegraphics[width=0.3\linewidth]{images/BothBoundaries}
  \label{fig:BoundarySide:BothBoundaries}
  }
\caption{Inner vs Outer Boundary of a Region}
\label{fig:BoundarySide}
\end{figure}


%%%%%%%%%%%%%%%
\begin{thebibliography}{9}

	\bibitem{criminisi}
	  A. Criminisi, P. Perez, K. Toyama,
	  \emph{Object Removal by Exemplar-Based Inpainting}.
	  Computer Vision and Pattern Recognition 2003

\end{thebibliography}

\end{document}